{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b704b660",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4df0e5f",
   "metadata": {},
   "source": [
    "## library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a1c95ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T04:34:40.283723Z",
     "start_time": "2023-05-31T04:34:37.938576Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import operator\n",
    "import wandb\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()\n",
    "\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import seaborn as sns \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.cm as cm\n",
    "from IPython.display import set_matplotlib_formats\n",
    "\n",
    "sns.set(style='white', context='notebook', palette='deep')\n",
    "line_color = ['#FFBF00','#FF7F50','#DE3163','#9FE2BF','#40E0D0','#6495ED','#117A65','#2471A3','#CCCCFF','#8E44AD','#CD5C5C' ,'#F08080','#FA8072' ,'#E9967A' ,'#FFA07A']\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.style.use(\"seaborn-white\")\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "#print(plt.rcParams['font.family'])\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f0ce72b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T04:34:43.538269Z",
     "start_time": "2023-05-31T04:34:42.750463Z"
    }
   },
   "outputs": [],
   "source": [
    "#? 통계\n",
    "#import statsmodels.api as sm\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from scipy.stats import mstats\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#? 평가지표\n",
    "import hydroeval as he\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c614a205",
   "metadata": {},
   "source": [
    "## function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1ca76fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T04:34:45.105437Z",
     "start_time": "2023-05-31T04:34:45.089490Z"
    }
   },
   "outputs": [],
   "source": [
    "# 예측과 실제 수위를 scatter plot해주는 함수 \n",
    "def scatter_plot(pred,answer):\n",
    "    x = pred\n",
    "    y = answer\n",
    "\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(7, 7))\n",
    "    rmse,nse,r2=metric(y,x)\n",
    "    axes.scatter(x, y, label='data') \n",
    "    lims = [np.min([axes.get_xlim(), axes.get_ylim()]), np.max([axes.get_xlim(), axes.get_ylim()]), ]\n",
    "    axes.plot(lims, lims, 'k--', alpha=0.75, zorder=0, label='parity')\n",
    "    axes.set_aspect('equal')\n",
    "    axes.set_xlabel('Prediction',fontsize=25)\n",
    "    axes.set_ylabel('Observation',fontsize=25)\n",
    "    handles, labels = axes.get_legend_handles_labels()\n",
    "    txt1=\"(a)   Jamsu bridge RMSE %.4f\"%rmse\n",
    "    axes.set_title(txt1, fontsize=25,loc='left')\n",
    "    axes.xaxis.set_tick_params(labelsize=20)\n",
    "    axes.yaxis.set_tick_params(labelsize=20)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "255766ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T04:34:45.859062Z",
     "start_time": "2023-05-31T04:34:45.854148Z"
    }
   },
   "outputs": [],
   "source": [
    "# 파일이 존재하는지 확인하는 함수 \n",
    "def check(filepath):\n",
    "    csv_files = glob(os.path.join(filepath, \"*.csv\"))\n",
    "    if len(csv_files) > 0:return 1\n",
    "    else:return 0\n",
    "    \n",
    "# 그래프에 rmse를 표시해주는 함수 \n",
    "def plot_rmse(ax, answer, preds, label):\n",
    "        ax.text(1.0, 0.95, '  {:.3f}  '.format(metric(answer,preds)[0]),\n",
    "                fontsize=93, ha='right', va='top', transform=ax.transAxes)\n",
    "        \n",
    "# rmse와 nse를 계산해주는 함수(m단위)\n",
    "def metric(y_true, y_pred):\n",
    "    y_true=y_true/100\n",
    "    y_pred=y_pred/100\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    nse=he.evaluator(he.nse, y_pred, y_true)\n",
    "    return rmse,nse,r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1aaf87b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T04:34:47.170463Z",
     "start_time": "2023-05-31T04:34:47.162491Z"
    }
   },
   "outputs": [],
   "source": [
    "# 선행시간, 이동평균, 윈도우에 맞게 데이터셋을 제공 \n",
    "def load_dataset(leadtime,moving_average,version):\n",
    "    \n",
    "    # 이동평균을 적용할 feature들 \n",
    "    select_features=['cd_br','hj_br','jn_br','tl_gh_br','flow','water','wl_js_br']\n",
    "    # feature engineering 할 유량들.\n",
    "    fe_list=['cd_br','hj_br','jn_br']\n",
    "    \n",
    "    x=pd.concat([train_data,test_data],axis=0)\n",
    "    x.reset_index(drop=True,inplace=True)\n",
    "    x=x.set_index('ymdhm')\n",
    "    x.index=pd.to_datetime(x.index)\n",
    "    \n",
    "    # 선행시간을 적용하기 위해 타겟을미뤄줌 \n",
    "    y=x['target']\n",
    "    x.drop('target',axis=1,inplace=True)\n",
    "    \n",
    "    # feature engineer을 안함(유량정보없음)\n",
    "    if(version==0):\n",
    "        x.drop(['fw_cd_br','fw_hj_br','fw_jn_br'],axis=1,inplace=True)\n",
    "    # feature engineering 함(유량정보있고, 팔당댐도 엔지니어링)\n",
    "    if(version==1):\n",
    "\n",
    "        # 월과 시간에 대한 feature도 추가해줌 \n",
    "        x['month'],x['hour']=x.index.month,x.index.hour\n",
    "\n",
    "        flow = PCA(n_components=1)\n",
    "        flow.fit(x[['tototf_pd_dam','inf_pd_dam']])\n",
    "        transformed_data = flow.transform(x[['tototf_pd_dam','inf_pd_dam']])  # 변환된 데이터\n",
    "        x['flow']=transformed_data\n",
    "        \n",
    "        water = PCA(n_components=1)\n",
    "        water.fit(x[['sfw_pd_dam','wl_pd_dam']])\n",
    "        transformed_data = water.transform(x[['sfw_pd_dam','wl_pd_dam']])  # 변환된 데이터\n",
    "        x['water']=transformed_data\n",
    "        \n",
    "        x.drop(['tototf_pd_dam','inf_pd_dam','sfw_pd_dam','wl_pd_dam','ecpc_pd_dam'],axis=1,inplace=True)\n",
    "        \n",
    "        fe_list=['cd_br','hj_br','jn_br']\n",
    "        for i in fe_list:\n",
    "            v_name = f\"{i}_pca\"  # 동적으로 생성할 변수명\n",
    "            f_name,w_name = \"fw_\"+i, 'wl_'+i\n",
    "            tmp=x[[f_name,w_name]]\n",
    "            globals()[v_name] = PCA(n_components=1)  # 변수 생성\n",
    "            globals()[v_name].fit(tmp)  # PCA 수행\n",
    "            transformed_data = globals()[v_name].transform(tmp)  # 변환된 데이터\n",
    "            x[i]=transformed_data\n",
    "            x.drop([f_name],axis=1,inplace=True)\n",
    "            if(moving_average<1): x.drop([w_name],axis=1,inplace=True)\n",
    "       \n",
    "    # 이동평균을 적용\n",
    "    if(moving_average>1):\n",
    "        for i in range(len(select_features)):\n",
    "            coln=select_features[i]+str(moving_average)+'ma'\n",
    "            x[coln] = x[select_features[i]].rolling(window=moving_average).mean()\n",
    "            if(i<3):x.drop('wl_'+select_features[i],axis=1,inplace=True)\n",
    "            \n",
    "    # train과 test를 다시 분리       \n",
    "    idx = x.index.get_loc('2022-06-21 00:00:00')\n",
    "    \n",
    "    # test를 위해 train과 test의 범위를 선행시간만큼 조정 \n",
    "    x_train=x[:idx]\n",
    "    x_test=x[idx:]\n",
    "    y_train = y[:idx]\n",
    "    \n",
    "    if(version==1 and moving_average==0):\n",
    "        x_train=x_train[1:]\n",
    "        y_train=y_train[1:]\n",
    "\n",
    "    # 이동평균을 적용하면 생기는 nan을 없애주기 위함 \n",
    "    if(moving_average!=0):\n",
    "        x_train=x_train[moving_average:]\n",
    "        y_train=y_train[moving_average:]\n",
    "        \n",
    "    x_train.reset_index(drop=True,inplace=True)\n",
    "    x_test.reset_index(drop=True,inplace=True)\n",
    "    y_train.reset_index(drop=True,inplace=True)\n",
    "        \n",
    "    features=['wl_js_br', 'pr_jg', 'pr_dg', 'pr_sj', 'tl_gh_br', 'month', 'hour',\n",
    "       'flow', 'water', 'cd_br', 'hj_br', 'jn_br']\n",
    "    \n",
    "    x_trains,y_trains,x_tests=[],[],[]\n",
    "    for i in tqdm(range(len(x_train)-12)):\n",
    "        x_trains.append(np.array(x_train.loc[i:i+11, features]).astype(float))\n",
    "        y_trains.append(np.array(y_train.loc[i+11+leadtime]).astype(float))\n",
    "        \n",
    "    for i in tqdm(range(len(x_test)-12)):\n",
    "        x_tests.append(np.array(x_test.loc[i:i+11, features]).astype(float))\n",
    "        \n",
    "    x_train = np.array(x_trains)\n",
    "    y_train = np.array(y_trains)    \n",
    "    x_test = np.array(x_tests)\n",
    "    \n",
    "    dataset=[x_train,x_test,y_train]\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7c701c9",
   "metadata": {},
   "source": [
    "# Data Load and Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7fc49400",
   "metadata": {},
   "source": [
    "# Refined data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bfdf47c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T04:34:54.340803Z",
     "start_time": "2023-05-31T04:34:53.192165Z"
    }
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"../data/new_Refined_data.csv\")\n",
    "train_data=pd.read_csv(\"../data/refined_train_data.csv\")\n",
    "test_data=pd.read_csv(\"../data/refined_test_data.csv\")\n",
    "answer=pd.read_csv(\"../data/answer.csv\")\n",
    "\n",
    "train_data['target']=train_data['wl_js_br']\n",
    "test_data['target']=0\n",
    "# answer\n",
    "\n",
    "train_data.drop(['wl_hg_br','fw_hg_br','wl_gj_br','wl_pd_br','fw_pd_br'],axis=1,inplace=True)\n",
    "test_data.drop(['wl_hg_br','fw_hg_br','wl_gj_br','wl_pd_br','fw_pd_br'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfa55030",
   "metadata": {},
   "outputs": [],
   "source": [
    "leadtime=1\n",
    "\n",
    "#data=load_dataset(leadtime,0,1)\n",
    "\n",
    "leadtime=str(leadtime)+'0'\n",
    "#np.save(f\"../data/numpy_data/leadtime({leadtime})/x_train.npy\",data[0])\n",
    "#np.save(f\"../data/numpy_data/leadtime({leadtime})/x_test.npy\",data[1])\n",
    "#np.save(f\"../data/numpy_data/leadtime({leadtime})/y_train.npy\",data[2])\n",
    "\n",
    "x_train=np.load(f\"../data/numpy_data/leadtime({leadtime})/x_train.npy\")\n",
    "x_test=np.load(f\"../data/numpy_data/leadtime({leadtime})/x_test.npy\")\n",
    "y_train=np.load(f\"../data/numpy_data/leadtime({leadtime})/y_train.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d2b2f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 12, 12)]          0         \n",
      "                                                                 \n",
      " tcn_1 (TCN)                 (None, 64)                336704    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 336,769\n",
      "Trainable params: 336,769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tcn import TCN\n",
    "\n",
    "def build_model():\n",
    "    inputs = tf.keras.Input(shape=(12, 12))    \n",
    "    x = TCN(nb_filters=64,\n",
    "                 kernel_size=3,\n",
    "                 nb_stacks=2,\n",
    "                 dilations=(1, 2, 4, 8, 16, 32, 64),\n",
    "                 padding='causal',\n",
    "                 use_skip_connections=True,\n",
    "                 dropout_rate=0.,\n",
    "                 return_sequences=False,                 \n",
    "                 kernel_initializer='he_normal',\n",
    "                 use_batch_norm=False,\n",
    "                 use_layer_norm=False,\n",
    "                 use_weight_norm=False,\n",
    "                 activation=\"tanh\")(inputs)        \n",
    "    outputs = tf.keras.layers.Dense(1, dtype=tf.float32)(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "optimizer = tf.optimizers.RMSprop(0.001)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=\"mse\", metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8a3fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, GRU, AveragePooling1D, GlobalAveragePooling1D,Dropout \n",
    "\n",
    "from tensorflow.compat.v1.keras.backend import get_session\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "\n",
    "input_shape = (x_train[0].shape[0], x_train[0].shape[1])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GRU(256, input_shape=input_shape, return_sequences=True))\n",
    "model.add(GRU(128))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "optimizer = tf.optimizers.RMSprop(0.001)\n",
    "\n",
    "model.compile(optimizer=optimizer,loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1def032c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "973/973 [==============================] - 39s 32ms/step - loss: 5861.0664 - root_mean_squared_error: 76.5576\n",
      "Epoch 2/1000\n",
      "973/973 [==============================] - 30s 31ms/step - loss: 216.8207 - root_mean_squared_error: 14.7248\n",
      "Epoch 3/1000\n",
      "973/973 [==============================] - 30s 31ms/step - loss: 154.0263 - root_mean_squared_error: 12.4107\n",
      "Epoch 4/1000\n",
      "973/973 [==============================] - 30s 31ms/step - loss: 132.1824 - root_mean_squared_error: 11.4971\n",
      "Epoch 5/1000\n",
      "973/973 [==============================] - 30s 31ms/step - loss: 112.1670 - root_mean_squared_error: 10.5909\n",
      "Epoch 6/1000\n",
      "973/973 [==============================] - 31s 31ms/step - loss: 108.1019 - root_mean_squared_error: 10.3972\n",
      "Epoch 7/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 98.0839 - root_mean_squared_error: 9.9037\n",
      "Epoch 8/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 88.8849 - root_mean_squared_error: 9.4279\n",
      "Epoch 9/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 87.6921 - root_mean_squared_error: 9.3644\n",
      "Epoch 10/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 82.6355 - root_mean_squared_error: 9.0904\n",
      "Epoch 11/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 77.1956 - root_mean_squared_error: 8.7861\n",
      "Epoch 12/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 79.6184 - root_mean_squared_error: 8.9229\n",
      "Epoch 13/1000\n",
      "973/973 [==============================] - 31s 31ms/step - loss: 72.1155 - root_mean_squared_error: 8.4921\n",
      "Epoch 14/1000\n",
      "973/973 [==============================] - 30s 31ms/step - loss: 73.5551 - root_mean_squared_error: 8.5764\n",
      "Epoch 15/1000\n",
      "973/973 [==============================] - 30s 31ms/step - loss: 70.7024 - root_mean_squared_error: 8.4085\n",
      "Epoch 16/1000\n",
      "973/973 [==============================] - 30s 31ms/step - loss: 67.6493 - root_mean_squared_error: 8.2249\n",
      "Epoch 17/1000\n",
      "973/973 [==============================] - 30s 31ms/step - loss: 68.1195 - root_mean_squared_error: 8.2535\n",
      "Epoch 18/1000\n",
      "973/973 [==============================] - 30s 31ms/step - loss: 66.4833 - root_mean_squared_error: 8.1537\n",
      "Epoch 19/1000\n",
      "973/973 [==============================] - 30s 31ms/step - loss: 63.3696 - root_mean_squared_error: 7.9605\n",
      "Epoch 20/1000\n",
      "973/973 [==============================] - 30s 31ms/step - loss: 63.6193 - root_mean_squared_error: 7.9762\n",
      "Epoch 21/1000\n",
      "973/973 [==============================] - 30s 31ms/step - loss: 76.2595 - root_mean_squared_error: 8.7327\n",
      "Epoch 22/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 60.4273 - root_mean_squared_error: 7.7735\n",
      "Epoch 23/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 61.2664 - root_mean_squared_error: 7.8273\n",
      "Epoch 24/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 60.2603 - root_mean_squared_error: 7.7628\n",
      "Epoch 25/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 57.4712 - root_mean_squared_error: 7.5810\n",
      "Epoch 26/1000\n",
      "973/973 [==============================] - 32s 33ms/step - loss: 56.8046 - root_mean_squared_error: 7.5369\n",
      "Epoch 27/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 55.8649 - root_mean_squared_error: 7.4743\n",
      "Epoch 28/1000\n",
      "973/973 [==============================] - 30s 31ms/step - loss: 59.1103 - root_mean_squared_error: 7.6883\n",
      "Epoch 29/1000\n",
      "973/973 [==============================] - 30s 31ms/step - loss: 120.1904 - root_mean_squared_error: 10.9631\n",
      "Epoch 30/1000\n",
      "973/973 [==============================] - 30s 31ms/step - loss: 63.0362 - root_mean_squared_error: 7.9395\n",
      "Epoch 31/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 60.8606 - root_mean_squared_error: 7.8013\n",
      "Epoch 32/1000\n",
      "973/973 [==============================] - 30s 31ms/step - loss: 57.2508 - root_mean_squared_error: 7.5664\n",
      "Epoch 33/1000\n",
      "973/973 [==============================] - 30s 31ms/step - loss: 58.6948 - root_mean_squared_error: 7.6613\n",
      "Epoch 34/1000\n",
      "973/973 [==============================] - 30s 31ms/step - loss: 52.9737 - root_mean_squared_error: 7.2783\n",
      "Epoch 35/1000\n",
      "973/973 [==============================] - 30s 31ms/step - loss: 55.2091 - root_mean_squared_error: 7.4303\n",
      "Epoch 36/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 58.6567 - root_mean_squared_error: 7.6588\n",
      "Epoch 37/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 61.5022 - root_mean_squared_error: 7.8423\n",
      "Epoch 38/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 53.7295 - root_mean_squared_error: 7.3300\n",
      "Epoch 39/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 56.1001 - root_mean_squared_error: 7.4900\n",
      "Epoch 40/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 59.2437 - root_mean_squared_error: 7.6970\n",
      "Epoch 41/1000\n",
      "973/973 [==============================] - 31s 31ms/step - loss: 58.1595 - root_mean_squared_error: 7.6262\n",
      "Epoch 42/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 57.3872 - root_mean_squared_error: 7.5754\n",
      "Epoch 43/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 54.5775 - root_mean_squared_error: 7.3877\n",
      "Epoch 44/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 54.3213 - root_mean_squared_error: 7.3703\n",
      "Epoch 45/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 52.8058 - root_mean_squared_error: 7.2668\n",
      "Epoch 46/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 53.1493 - root_mean_squared_error: 7.2904\n",
      "Epoch 47/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 56.5041 - root_mean_squared_error: 7.5169\n",
      "Epoch 48/1000\n",
      "973/973 [==============================] - 31s 31ms/step - loss: 50.6690 - root_mean_squared_error: 7.1182\n",
      "Epoch 49/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 52.1518 - root_mean_squared_error: 7.2216\n",
      "Epoch 50/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 51.9803 - root_mean_squared_error: 7.2097\n",
      "Epoch 51/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 50.4974 - root_mean_squared_error: 7.1061\n",
      "Epoch 52/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 50.7255 - root_mean_squared_error: 7.1222\n",
      "Epoch 53/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 49.0614 - root_mean_squared_error: 7.0044\n",
      "Epoch 54/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 48.0635 - root_mean_squared_error: 6.9328\n",
      "Epoch 55/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 50.2935 - root_mean_squared_error: 7.0918\n",
      "Epoch 56/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 48.9358 - root_mean_squared_error: 6.9954\n",
      "Epoch 57/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 53.3321 - root_mean_squared_error: 7.3029\n",
      "Epoch 58/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 50.4712 - root_mean_squared_error: 7.1043\n",
      "Epoch 59/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 49.2270 - root_mean_squared_error: 7.0162\n",
      "Epoch 60/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 48.8300 - root_mean_squared_error: 6.9878\n",
      "Epoch 61/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 46.6388 - root_mean_squared_error: 6.8293\n",
      "Epoch 62/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 49.2607 - root_mean_squared_error: 7.0186\n",
      "Epoch 63/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 46.6140 - root_mean_squared_error: 6.8274\n",
      "Epoch 64/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 47.9360 - root_mean_squared_error: 6.9236\n",
      "Epoch 65/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 47.8925 - root_mean_squared_error: 6.9204\n",
      "Epoch 66/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 47.1616 - root_mean_squared_error: 6.8674\n",
      "Epoch 67/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 48.0565 - root_mean_squared_error: 6.9323\n",
      "Epoch 68/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 46.9512 - root_mean_squared_error: 6.8521\n",
      "Epoch 69/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 46.8272 - root_mean_squared_error: 6.8430\n",
      "Epoch 70/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 46.8035 - root_mean_squared_error: 6.8413\n",
      "Epoch 71/1000\n",
      "973/973 [==============================] - 31s 32ms/step - loss: 50.7737 - root_mean_squared_error: 7.1256\n",
      "Epoch 72/1000\n",
      "973/973 [==============================] - 31s 31ms/step - loss: 50.8971 - root_mean_squared_error: 7.1342\n",
      "Epoch 73/1000\n",
      "393/973 [===========>..................] - ETA: 18s - loss: 51.5216 - root_mean_squared_error: 7.1779"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mfit(x_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m512\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\water_project\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\water_project\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\water_project\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\water_project\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\water_project\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\water_project\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\water_project\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\water_project\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\water_project\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=1000, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2e4630",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fd0adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model.save('tcn_model(1000).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898c2499",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=pd.DataFrame(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed7228a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(15,10))\n",
    "plt.plot(y_pred) # 선행시간 10m\n",
    "plt.plot(answer) # 선행시간 30m\n",
    "plt.legend(['pred','answer'],fontsize=20)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae6b740",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['wl_js_br', 'pr_jg', 'pr_dg', 'pr_sj', 'tl_gh_br', 'month', 'hour',\n",
    "       'flow', 'water', 'cd_br', 'hj_br', 'jn_br']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffb004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "np.bool = np.bool_\n",
    "np.int = np.int_\n",
    "\n",
    "explainer = shap.DeepExplainer(model, x_train[:150])\n",
    "\n",
    "shap_values = explainer.shap_values(x_test[:100],check_additivity=False)\n",
    "\n",
    "shap_valuesnp = np.array(shap_values) \n",
    "shap_valuesnp = np.reshape(shap_valuesnp,(int(shap_valuesnp.shape[1]),int(shap_valuesnp.shape[2]),int(shap_valuesnp.shape[3]))) \n",
    "shap_abs = np.absolute(shap_valuesnp) \n",
    "sum_0 = np.sum(shap_abs,axis=0) \n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(10, 12))\n",
    "axs = axs.flatten()\n",
    "x_pos=[i for i in range(0,12)]\n",
    "for i, ax in enumerate(axs):\n",
    "    ax.barh(x_pos, sum_0[5 - i])\n",
    "    ax.set_yticks(x_pos)\n",
    "    ax.set_yticklabels(features)\n",
    "    ax.set_title(f\"time-{i+1}\")\n",
    "    ax.set_xlim(0, 1500)  # x축 범위 설정\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show();\n",
    "\n",
    "\n",
    "#shap.summary_plot(shap_values[0], plot_type = 'bar', feature_names = features*6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb03331f",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_shap_values = np.mean(shap_valuesnp, axis=0)\n",
    "\n",
    "shap.summary_plot(average_shap_values, plot_type = 'bar', feature_names = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8c926a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.waterfall_plot(shap_values)\n",
    "shap.plots.bar(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091f5675",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "water_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "797.766px",
    "left": "461.969px",
    "top": "132.438px",
    "width": "240.375px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 680.844,
   "position": {
    "height": "40px",
    "left": "1335.3px",
    "right": "20px",
    "top": "183.969px",
    "width": "582px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
