{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from math import sqrt\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# 시각화\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "plt.style.use([\"seaborn-v0_8-muted\"])\n",
    "plt.rc('font', family='Malgun Gothic')\n",
    "matplotlib.rc('axes',unicode_minus=False)\n",
    "seaborn_style = [style for style in matplotlib.style.available if \"seaborn\" in style]\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 모델\n",
    "from pycaret.regression import *\n",
    "from pycaret.regression import load_model\n",
    "import joblib\n",
    "\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "from lightgbm import plot_importance\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "### 토치확인\n",
    "print(\"pytorch cuda 여부\")\n",
    "print(torch.cuda.is_available())\n",
    "print('#'*50)\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(\"tensorflow cuda 여부\")\n",
    "print(device_lib.list_local_devices())\n",
    "print('#'*50)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # -1이면 cpu사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppd_data=pd.read_csv('../data/ppd_data.csv')\n",
    "ppd_data.set_index(\"ymdhm\",inplace=True)\n",
    "ppd_data.index=pd.to_datetime(ppd_data.index)\n",
    "\n",
    "answer=pd.read_csv(\"../data/2023_js_answer.csv\")\n",
    "answer['ymdhm']=pd.to_datetime(answer['ymdhm'])\n",
    "answer.set_index('ymdhm',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "트리기반의 모델을 이용하여 rmse와 시간을 비교하여 베이스라인 모델을 선정.<br>\n",
    "Pycaret을 이용하여 간단하게 비교."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp=ppd_data.copy()\n",
    "\n",
    "# TARGET_BRIDGE = 'wl_jamsu'\n",
    "# tmp[\"prev_\"+TARGET_BRIDGE]=tmp[TARGET_BRIDGE].copy()\n",
    "# X_train = tmp.drop(columns=[TARGET_BRIDGE]).shift(1)\n",
    "# X_train = X_train.iloc[1:]\n",
    "# y_train = tmp[TARGET_BRIDGE].iloc[1:]\n",
    "# train=pd.concat([X_train,y_train],axis=1)\n",
    "\n",
    "# # 모델을 선정하기위해 automl pycaret을 이용하여 선정. -> 한대교만을 기준으로 선정하였음. \n",
    "# baseline = setup(data=train, target=TARGET_BRIDGE, fold_strategy = 'kfold',fold=5, data_split_shuffle=True, use_gpu=True, verbose=False)\n",
    "# baseline_res = compare_models(include = ['lightgbm','xgboost','catboost','rf'], sort='rmse')\n",
    "# baseline_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model train & tune & inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해당 폴더에 파일이 있는지 없는지 확인\n",
    "def check_file(path):\n",
    "    return os.path.isfile(path)\n",
    "# 평가지수 rmse/r_squared\n",
    "def metrics(y_true, y_pred):\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    r_squared = r2_score(y_true, y_pred)\n",
    "    score=rmse/r_squared\n",
    "    return 'score', score, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance(leadtime,month, max_n):\n",
    "    \"\"\"\n",
    "    lgbm 모델의 feature importance를 불러오는 함수.\n",
    "    \"\"\"\n",
    "    fig=plt.figure(figsize=(10,6))\n",
    "    if(isinstance(month,int)):prefix=f\"month={month}\"\n",
    "    else:prefix=month\n",
    "    model = joblib.load(f'../model/{TARGET_BRIDGE}/leadtime({leadtime})_{PARAMS_SIZE}/tuned_model({prefix}).pkl')\n",
    "    importance = plot_importance(model, max_num_features=max_n, figsize=(6, 4))\n",
    "    plt.title(f'month={month}, leadtime={leadtime} feature importance')\n",
    "    return fig\n",
    "\n",
    "def plot_compare(answer,data_combinations):\n",
    "    \"\"\"\n",
    "    여러 조합의 실제 데이터와 예측 데이터를 비교하여 행으로 시각화해주는 함수\n",
    "    1. scatter plot /  2. line plot\n",
    "    \"\"\"\n",
    "    num_combinations = len(data_combinations)\n",
    "\n",
    "    fig, axs = plt.subplots(num_combinations, 2, figsize=(20, 7*num_combinations), sharey=True,gridspec_kw={'width_ratios': [1, 2]})\n",
    "    titles=['Parameter:S','Parameter:M','Parameter:L']\n",
    "\n",
    "    for i, pred_data in enumerate(data_combinations):\n",
    "        # 오차(rmse) 계산\n",
    "        rmse = mean_squared_error(answer[TARGET_BRIDGE], pred_data['pred_target'], squared=False)\n",
    "\n",
    "        # 서브플롯 설정\n",
    "        ax1 = axs[i, 0] if num_combinations > 1 else axs[0]\n",
    "        ax2 = axs[i, 1] if num_combinations > 1 else axs[1]\n",
    "\n",
    "        # Scatter plot\n",
    "        ax1.scatter(answer[TARGET_BRIDGE], pred_data['pred_target'])\n",
    "        ax1.set_xlabel('Time')\n",
    "        ax1.set_ylabel('Water Level')\n",
    "        ax1.set_title(f'{titles[i]}')\n",
    "        ax1.set_aspect('equal', adjustable='box')\n",
    "\n",
    "        # Line plot\n",
    "        ax2.text(0.05, 0.95, '  {:.3f}  '.format(rmse), fontsize=15, ha='right', va='top', transform=ax2.transAxes)\n",
    "        ax2.plot(answer.index, answer[TARGET_BRIDGE], label='Actual', color='blue', alpha=0.5)\n",
    "        ax2.plot(answer.index, pred_data['pred_target'], label='Predicted', color='red', linestyle='--', alpha=0.5)\n",
    "        #ax2.set_xlabel('Time')\n",
    "        #ax2.set_ylabel('Water Level')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_month(answer_data,pred_data,len_m):\n",
    "    \"\"\"\n",
    "    1. scatter plot: 실제 데이터와 예측 데이터의 오차를 월별로 보여주는 함수\n",
    "    2. bar plot: 예측 데이터의 오차를 월별로 보여주는 함수 \n",
    "    \n",
    "    \"\"\"\n",
    "    used_data=pd.concat([answer_data,pred_data],axis=1)\n",
    "    used_data.index=pd.to_datetime(used_data.index)\n",
    "\n",
    "    grouped = used_data.groupby(used_data.index.month)\n",
    "    year = used_data.index[0].year\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=len_m//2, ncols=2, figsize=(20, len_m*2))\n",
    "    axes = axes.ravel()  \n",
    "    month_names = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \n",
    "                \"September\", \"October\", \"November\", \"December\"]\n",
    "\n",
    "    month_rmse = []\n",
    "    \n",
    "    # Line plot\n",
    "    for (month, m_data), ax in zip(grouped, axes):\n",
    "        actual = m_data[TARGET_BRIDGE]\n",
    "        predicted = m_data['pred_target']\n",
    "        \n",
    "        rmse = mean_squared_error(actual, predicted, squared=False)\n",
    "        month_rmse.append(rmse)\n",
    "        \n",
    "        ax.plot(m_data.index, actual, label='Actual', color='blue', alpha=0.5)\n",
    "        ax.plot(m_data.index, predicted, label='Predicted', color='red', linestyle='--', alpha=0.5)\n",
    "        ax.set_title(f'{TARGET_BRIDGE}{month_names[month-1]}, {year} - RMSE: {rmse:.2f}')\n",
    "        ax.set_xlabel('Time')\n",
    "        ax.set_ylabel('Water Level')\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.title(f'{TARGET_BRIDGE} PREDICT')\n",
    "    plt.show();\n",
    "    \n",
    "    # Bar plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(range(len(month_rmse)), month_rmse, color='skyblue', edgecolor='black')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.xlabel('Month')\n",
    "    plt.title(f'RMSE by Month for {year}')\n",
    "    plt.xticks(range(len(month_rmse)), [month_names[i-1] for i in grouped.groups.keys()], rotation=45)\n",
    "    plt.grid(axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show();\n",
    "    \n",
    "# 3개의 모델(월별, 기간별, 전체)을 이용하여 test 셋의 rmse를 가장 잘 예측한 모델을 확인.\n",
    "def finalize_modeling(dataset,leadtime,bridge,Params):\n",
    "    overall_rmse_list = []\n",
    "    print(\"#\" * 50)\n",
    "    print(f\"{bridge} Predict report for Leadtime {leadtime}-{Params}:\\n\")\n",
    "    rmse_best = pd.DataFrame(index=range(1, 10), columns=['Model 1', 'Model 2', 'Model 3', 'Best Model'])\n",
    "    for month in range(1, 10):\n",
    "        best_rmse, best_model_name = float('inf'), None\n",
    "        for i, model in enumerate(dataset):\n",
    "            model.index = pd.to_datetime(model.index)\n",
    "            model_month = model[model.index.month == month]\n",
    "            answer_month = answer[answer.index.month == month]['wl_'+bridge]\n",
    "\n",
    "            if not model_month.empty and not answer_month.empty:\n",
    "                rmse = mean_squared_error(answer_month, model_month,squared=False)\n",
    "                rmse_best.loc[month, f'Model {i+1}'] = rmse\n",
    "\n",
    "                if rmse < best_rmse:\n",
    "                    best_rmse, best_model_name = rmse, f'Model {i+1}'\n",
    "\n",
    "        rmse_best.loc[month, 'Best Model'] = best_model_name\n",
    "\n",
    "    best_model_rmse = [rmse_best.loc[month, best_model] for month, best_model in enumerate(rmse_best['Best Model'], start=1)]\n",
    "    overall_rmse = np.sqrt(np.mean(np.square(best_model_rmse)))\n",
    "    overall_rmse_list.append(overall_rmse)\n",
    "    rmse_best.columns=['Monthly','Flood','Total','Best Model']\n",
    "    \n",
    "    return rmse_best,overall_rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(input_data, month_list):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - input_data: 2023 제외한 특정 month 데이터 \n",
    "    - leadtime: 선행시간\n",
    "    - month_list: 학습하고자하는 month \n",
    "\n",
    "    Returns:\n",
    "    - X_train: 학습 데이터 features\n",
    "    - y_train: 학습 데이터 target\n",
    "    \"\"\"\n",
    "    \n",
    "    X_train = input_data.drop(columns=[TARGET_BRIDGE]).shift(LEADTIME//10)\n",
    "\n",
    "    y_train = input_data[TARGET_BRIDGE].iloc[LEADTIME//10:]\n",
    "\n",
    "    X_train = X_train.iloc[LEADTIME//10:]\n",
    "    \n",
    "    X_train=X_train[X_train['month'].isin(month_list)]\n",
    "    y_train=y_train[X_train.index]\n",
    "\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_base_model(train_data):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - train_data: 학습 데이터 \n",
    "    - leadtime: 선행시간\n",
    "\n",
    "    Returns:\n",
    "    - model: 베이스라인 모델(성능비교용)\n",
    "    \"\"\"\n",
    "    if(MODE=='train'):\n",
    "        params={\n",
    "            \"num_leaves\" : 1023,\n",
    "            \"max_depth\" : 15,\n",
    "            \"learning_rate\" : 0.23,\n",
    "            \"n_estimators\": 50,\n",
    "            \"min_child_samples\" :10,\n",
    "            \"reg_lambda\" : 7,\n",
    "            \"colsample_bytree\" : 0.5,\n",
    "        }\n",
    "    else:\n",
    "        prev_model = joblib.load(f'../model/{TARGET_BRIDGE}/leadtime(10)_{PARAMS_SIZE}/tuned_model({PRIFIX}).pkl')\n",
    "        params = prev_model.get_params()\n",
    "        model = LGBMRegressor(**params)\n",
    "        model.fit(train_data[0], train_data[1])\n",
    "        return model\n",
    "        \n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(train_data[0], train_data[1], test_size=0.2, random_state=624)\n",
    "\n",
    "    model = LGBMRegressor(**params,random_state=624,objective= 'rmse',device='gpu',verbose=-1)\n",
    "    model.fit(X_train,y_train, eval_set=[(X_valid, y_valid)], eval_metric=metrics)\n",
    "    \n",
    "    y_pred = model.predict(X_valid, num_iteration=model.best_iteration_)\n",
    "    print(f'Valid Score: {metrics(y_valid, y_pred)[1]}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStoppingCallback(object):\n",
    "    # stackoverflow에서 가져옴. https://github.com/optuna/optuna/issues/1001\n",
    "    # optuna의 early stopping callback 적용\n",
    "    # 평가지수가 감소하는 방향으로 학습하면 minimize\n",
    "    # 평가지수가 증가하는 방향으로 학습하면 maximize\n",
    "\n",
    "    def __init__(self, early_stopping_rounds: int, direction: str = \"minimize\") -> None:\n",
    "        self.early_stopping_rounds = early_stopping_rounds\n",
    "        self._iter = 0\n",
    "        if direction == \"minimize\":\n",
    "            self._operator = operator.lt\n",
    "            self._score = np.inf\n",
    "        elif direction == \"maximize\":\n",
    "            self._operator = operator.gt\n",
    "            self._score = -np.inf\n",
    "        else:\n",
    "            ValueError(f\"invalid direction: {direction}\")\n",
    "\n",
    "    def __call__(self, study: optuna.Study, trial: optuna.Trial) -> None:\n",
    "        \"\"\"Do early stopping.\"\"\"\n",
    "        if self._operator(study.best_value, self._score):\n",
    "            self._iter = 0\n",
    "            self._score = study.best_value\n",
    "        else:\n",
    "            self._iter += 1\n",
    "\n",
    "        if self._iter >= self.early_stopping_rounds:\n",
    "            study.stop()\n",
    "            \n",
    "def weighted_mse(alpha=1):\n",
    "    def weighted_mse_fixed(label, pred):\n",
    "        residual = (label - pred).astype(\"float\")\n",
    "        loss = np.where(residual > 0, alpha * residual**2, residual**2)\n",
    "        return np.mean(loss)\n",
    "\n",
    "    return weighted_mse_fixed\n",
    "\n",
    "# optuna의 목적함수\n",
    "def objective(trial, X, y):\n",
    "    \n",
    "    param_ranges = {\n",
    "        'S': (10, 50, 3, 15, 0.01, 0.1, 50, 200, 5, 20, 0.1, 1.0, 0.6, 1.0),\n",
    "        'M': (20, 70, 5, 20, 0.005, 0.1, 100, 300, 10, 30, 0.05, 0.5, 0.5, 1.0),\n",
    "        'L': (30, 100, 8, 25, 0.001, 0.1, 150, 400, 15, 40, 0.01, 0.3, 0.4, 1.0),\n",
    "        # NUM_LEAVES,MAX_DEPTH,LR,N_ESTIMATORS,MIN_CHILD_SAMPLES,REG_LAMBDA,COLSAMPLE_BYTREE,DEVIDE\n",
    "    }\n",
    "\n",
    "    params_optuna = {\n",
    "        \"num_leaves\": trial.suggest_int('num_leaves', *param_ranges[PARAMS_SIZE][:2]),\n",
    "        \"max_depth\": trial.suggest_int('max_depth', *param_ranges[PARAMS_SIZE][2:4]),\n",
    "        \"learning_rate\": trial.suggest_float('learning_rate', *param_ranges[PARAMS_SIZE][4:6]),\n",
    "        \"n_estimators\": trial.suggest_int('n_estimators', *param_ranges[PARAMS_SIZE][6:8]),\n",
    "        \"min_child_samples\": trial.suggest_int('min_child_samples', *param_ranges[PARAMS_SIZE][8:10]),\n",
    "        \"reg_lambda\": trial.suggest_float('reg_lambda', *param_ranges[PARAMS_SIZE][10:12]),\n",
    "        \"colsample_bytree\": trial.suggest_float('colsample_bytree', *param_ranges[PARAMS_SIZE][12:]),\n",
    "        \"device\": 'gpu',\n",
    "    }\n",
    "\n",
    "    model = LGBMRegressor(**params_optuna,verbose=-1)\n",
    "\n",
    "    folds = KFold(n_splits=5, random_state=624, shuffle=True)\n",
    "    losses = []\n",
    "\n",
    "    for train_idx, valid_idx in folds.split(X, y):\n",
    "        X_train = X.iloc[train_idx, :]\n",
    "        y_train = y.iloc[train_idx]\n",
    "\n",
    "        X_valid = X.iloc[valid_idx, :]\n",
    "        y_valid = y.iloc[valid_idx]\n",
    "\n",
    "        model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], eval_metric=metrics)\n",
    "        preds = model.predict(X_valid)\n",
    "        \n",
    "        loss =  weighted_mse()(y_valid, preds)\n",
    "        losses.append(loss)\n",
    "        \n",
    "    return np.mean(losses)\n",
    "\n",
    "def make_tune_model(train_data):\n",
    "    # optuna에 인자를 넘기고 싶을 경우 partial 사용\n",
    "    opt_func = partial(objective, X=train_data[0], y=train_data[1]) \n",
    "\n",
    "    K = 5 \n",
    "    sampler = TPESampler(seed=624)\n",
    "    \n",
    "    study = optuna.create_study(direction=\"minimize\", # 최소/최대 어느 방향의 최적값을 구할 건지.\n",
    "                                sampler=sampler,\n",
    "                                study_name=f\"{EXP_NAME}\",\n",
    "                                storage=f\"sqlite:///study_record/{EXP_NAME}.sqlite3\",\n",
    "                                load_if_exists=True) \n",
    "    early_stopping = EarlyStoppingCallback(15, direction='minimize')\n",
    "    study.optimize(opt_func, n_trials=EPOCH, callbacks=[early_stopping])\n",
    "    \n",
    "    print(\"Tuned train Score: %.4f\" % study.best_value) # best score 출력\n",
    "    print(\"Tuned params: \", study.best_trial.params) # best score일 때의 하이퍼파라미터들\n",
    "    \n",
    "    best_params = study.best_params\n",
    "    best_model = LGBMRegressor(**best_params,random_state=624,objective= 'rmse',device='gpu', verbose=-1)\n",
    "    best_model.fit(train_data[0], train_data[1])\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_input(data):\n",
    "    # 특정 시점의 데이터를 예측하기 위한, 학습 데이터 준비(선행시간별로 달라지기 때문) \n",
    "    start_time = datetime(2023, 1, 1) - timedelta(minutes=LEADTIME)\n",
    "    \n",
    "    input_data = data[data.index >= start_time.strftime('%Y-%m-%d %H:%M:%S')]\n",
    "    \n",
    "    input_data.drop([TARGET_BRIDGE],axis=1,inplace=True)\n",
    "    \n",
    "    return input_data\n",
    "\n",
    "def make_pred(data, model, month_list):\n",
    "    \"\"\"\n",
    "    각 모델로 2023년 전체를 예측한뒤, 각 모델에 맞는 특정월 결과만 가져옴.\n",
    "    \"\"\"\n",
    "    input_data = get_model_input(data)\n",
    "    y_pred = model.predict(input_data,verbose=0)\n",
    "    y_pred=pd.DataFrame(y_pred[:-(LEADTIME//10)],index=answer.index,columns=['pred_target'])\n",
    "    y_pred.index=pd.to_datetime(y_pred.index)\n",
    "    y_pred['month']=y_pred.index.month\n",
    "    y_pred=y_pred[y_pred['month'].isin(month_list)]\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_wl_level(train_data,data,month_list):\n",
    "    print(\"#\"*50)\n",
    "    print(f\"{TARGET_BRIDGE} {PRIFIX}({LEADTIME}) predict start\")\n",
    "    monthly_train= prepare_datasets(train_data,month_list)\n",
    "    if((check_file(f\"../model/{TARGET_BRIDGE}/leadtime({LEADTIME})_{PARAMS_SIZE}/tuned_model({PRIFIX}).pkl\")!=1) | (MODE=='test')):\n",
    "        model=make_base_model(monthly_train)\n",
    "        #joblib.dump(base_model, f'../model/leadtime({leadtime})/base_model(month={month}).pkl')\n",
    "        if(MODE=='train'):model=make_tune_model(monthly_train)\n",
    "        if(SAVE==True):joblib.dump(model, f\"../model/{TARGET_BRIDGE}/leadtime({LEADTIME})_{PARAMS_SIZE}/tuned_model({PRIFIX}).pkl\")\n",
    "    pred=make_pred(data,model,month_list)\n",
    "    if(SAVE==True):pred.to_csv(f'../result/{TARGET_BRIDGE}/leadtime({LEADTIME})_{PARAMS_SIZE}/(lt={LEADTIME},{PRIFIX})_predict.csv')\n",
    "    print(f\"{TARGET_BRIDGE} {PRIFIX}({LEADTIME}) predict end\")\n",
    "    return pred\n",
    "\n",
    "def train(data,leadtime,model_num,params_size,mode,save=True):\n",
    "    \n",
    "    global EXP_NAME\n",
    "    global PRIFIX\n",
    "    global LEADTIME\n",
    "    global MODEL_NUM\n",
    "    global PARAMS_SIZE\n",
    "    global MODE\n",
    "    global SAVE\n",
    "    \n",
    "    LEADTIME,MODEL_NUM,PARAMS_SIZE,MODE,SAVE=leadtime,model_num,params_size,mode,save\n",
    "    \n",
    "    if(MODE=='train'):\n",
    "        check_task=int(input(f\"Check Option \\n PARAMS_SIZE={PARAMS_SIZE}, MODEL_NUM={MODEL_NUM}, 선행시간={LEADTIME}분, 타겟={TARGET_BRIDGE},MODE={MODE} \\n IF want continue enter 1 else 0\"))\n",
    "        if(check_task==0):\n",
    "            print(\"Check the option\")\n",
    "            return \n",
    "    os.makedirs(f\"../model/{TARGET_BRIDGE}/leadtime({LEADTIME})_{PARAMS_SIZE}\",exist_ok=True)\n",
    "    os.makedirs(f\"../result/{TARGET_BRIDGE}/leadtime({LEADTIME})_{PARAMS_SIZE}\",exist_ok=True)\n",
    "    \n",
    "    data[\"prev_\"+TARGET_BRIDGE]=data[TARGET_BRIDGE].copy()\n",
    "    train_data = data[:f\"2023-01-01 00:00:00\"]\n",
    "    \n",
    "    print(\"#\"*100)\n",
    "    print(\"#\"*100)\n",
    "    print(f\"{TARGET_BRIDGE} Leadtime {LEADTIME} modeling start\")\n",
    "    \n",
    "    f_name=[['0','1','2','3','4','5','6','7','8','9'],['비홍수기','홍수기'],'전체']\n",
    "    tmp_result=[]\n",
    "    # 각 월마다 따로 학습 및 병합\n",
    "    if(MODEL_NUM==1):\n",
    "        for month in range(1,10):\n",
    "            EXP_NAME=f\"{TARGET_BRIDGE}(lt={LEADTIME},m={month},PARAMS_SIZE={PARAMS_SIZE})\"\n",
    "            PRIFIX=f\"month={f_name[0][month]}\"\n",
    "            pred=predict_wl_level(train_data,data,[month])\n",
    "            tmp_result.append(pred)\n",
    "    # 홍수기와 비홍수기 나눠서 학습 및 병합\n",
    "    elif(MODEL_NUM==2):\n",
    "        # 비홍수기\n",
    "        month=[1,2,3,4,5,10,11,12]\n",
    "        EXP_NAME=f\"{TARGET_BRIDGE}(lt={LEADTIME},m=비홍수기,PARAMS_SIZE={PARAMS_SIZE})\"\n",
    "        PRIFIX=f_name[1][0]\n",
    "        pred=predict_wl_level(train_data,data,month)\n",
    "        tmp_result.append(pred)\n",
    "        \n",
    "        month=[6,7,8,9]\n",
    "        EXP_NAME=f\"{TARGET_BRIDGE}(lt={LEADTIME},m=홍수기,PARAMS_SIZE={PARAMS_SIZE})\"\n",
    "        PRIFIX=f_name[1][1]\n",
    "        pred=predict_wl_level(train_data,data,month)\n",
    "        tmp_result.append(pred)\n",
    "    # 전체 월로 학습 \n",
    "    elif(MODEL_NUM==3):\n",
    "        month=[1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "        EXP_NAME=f\"{TARGET_BRIDGE}(lt={LEADTIME},m=전체,PARAMS_SIZE={PARAMS_SIZE})\"\n",
    "        PRIFIX=f_name[2]\n",
    "        pred=predict_wl_level(train_data,data,month)\n",
    "        tmp_result.append(pred)\n",
    "        \n",
    "    final_result = pd.concat(tmp_result)\n",
    "    final_result.drop(['month'],axis=1,inplace=True)\n",
    "    \n",
    "    return final_result "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 잠수교 모델학습 및 추론(2023 1~9월)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_BRIDGE='wl_jamsu'\n",
    "EPOCH=100\n",
    "\n",
    "class LeadtimeModel:\n",
    "    \n",
    "    def __init__(self, data, leadtime, mode='test'):\n",
    "        \"\"\"\n",
    "        data=input data\n",
    "        leadtime=predict leadtime\n",
    "        mode= 'train'이면 optuna 하이퍼파라미터 튜닝까지. 'test'면 저장된 최적 파라미터를 불러와서 학습\n",
    "        \"\"\"\n",
    "        self.data=data\n",
    "        self.leadtime = leadtime\n",
    "        self.mode=mode\n",
    "        # 모델이 존재하면 load\n",
    "        try:\n",
    "            self.model_S=self.load('S')\n",
    "            self.model_M=self.load('M')\n",
    "            self.model_L=self.load('L')\n",
    "        # 모델이 존재하지 않으면 train\n",
    "        except:\n",
    "            self.train()\n",
    "    # 각 파라미터 크기별로 3개의 모델(월별,기간별,전체)를 생성 --> 총 9개의 모델을 생성하는 train.\n",
    "    # (선행시간10분)을 튜닝하면서 얻은 하이퍼파라미터를 이용하여 학습 진행     \n",
    "    def train(self,save=True):\n",
    "        \"\"\"\n",
    "        save= True면 모델 저장 및 csv 저장까지 False면 저장하지 않고 반환만.\n",
    "        \"\"\"\n",
    "        self.model_S=self.train_model('S',save)\n",
    "        self.model_M=self.train_model('M',save)\n",
    "        self.model_L=self.train_model('L',save)\n",
    "        self.score_S,self.best_score_S=self.show_score(self.model_S,'S')\n",
    "        self.score_M,self.best_score_M=self.show_score(self.model_M,'M')\n",
    "        self.score_L,self.best_score_L=self.show_score(self.model_L,'L')\n",
    "    \n",
    "    def train_model(self,params_size,save):\n",
    "        monthly = train(self.data,leadtime=self.leadtime, model_num=1, params_size=params_size,mode=self.mode,save=save)\n",
    "        flood = train(self.data,leadtime=self.leadtime, model_num=2, params_size=params_size,mode=self.mode,save=save)\n",
    "        total = train(self.data,leadtime=self.leadtime, model_num=3, params_size=params_size,mode=self.mode,save=save)\n",
    "\n",
    "        lt_list = [monthly, flood, total]\n",
    "\n",
    "        return lt_list\n",
    "    \n",
    "    # 이미 결과가 존재할 경우 각 모델에 맞는 결과를 불러옴 \n",
    "    def load(self,params_size):\n",
    "        months=[]\n",
    "        path=f\"../result/wl_jamsu/leadtime({self.leadtime})\"\n",
    "        \n",
    "        for month in range(1,10):\n",
    "            tmp=pd.read_csv(f'{path}_{params_size}/(lt={self.leadtime},month={month})_predict.csv')\n",
    "            tmp['ymdhm'] = pd.to_datetime(tmp['ymdhm'])\n",
    "            tmp = tmp[tmp['ymdhm'].dt.month == month]   \n",
    "            months.append(tmp)\n",
    "        result_S = pd.concat(months,ignore_index=True)\n",
    "        result_S.sort_values(by='ymdhm',inplace=True)\n",
    "        result_S.drop(['month'],axis=1,inplace=True)\n",
    "        \n",
    "        tmp=pd.read_csv(f'{path}_{params_size}/(lt={self.leadtime},비홍수기)_predict.csv')\n",
    "        tmp['ymdhm'] = pd.to_datetime(tmp['ymdhm'])\n",
    "        tmp = tmp[tmp['ymdhm'].dt.month.isin([1,2,3,4,5])]\n",
    "        tmp2=pd.read_csv(f'{path}_{params_size}/(lt={self.leadtime},홍수기)_predict.csv')\n",
    "        tmp2['ymdhm'] = pd.to_datetime(tmp2['ymdhm'])\n",
    "        tmp2 = tmp2[tmp2['ymdhm'].dt.month.isin([6,7,8,9])]\n",
    "        result_M = pd.concat([tmp,tmp2])\n",
    "        result_M.sort_values(by='ymdhm',inplace=True)\n",
    "        result_M.drop(['month'],axis=1,inplace=True)\n",
    "        \n",
    "        result_L=pd.read_csv(f'{path}_{params_size}/(lt={self.leadtime},전체)_predict.csv')\n",
    "        result_L['ymdhm'] = pd.to_datetime(result_L['ymdhm'])\n",
    "        result_L.sort_values(by='ymdhm',inplace=True)\n",
    "        result_L.drop(['month'],axis=1,inplace=True)\n",
    "        \n",
    "        return [result_S,result_M,result_L]\n",
    "    \n",
    "    \n",
    "    def show_plot(self,model):\n",
    "        plot_compare(answer,model)\n",
    "        \n",
    "    def show_score(self,model,params):\n",
    "        result,best_score=finalize_modeling(model,leadtime=self.leadtime,bridge='jamsu',Params=params)\n",
    "        return result,best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 선행시간 10분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선행시간 10분 모델학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadtime10=LeadtimeModel(ppd_data,10,'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선행시간 10분 모델결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 선행시간 10분 모델 결과 PLOT\n",
    "leadtime10.show_plot(leadtime10.model_S)\n",
    "leadtime10.show_plot(leadtime10.model_M)\n",
    "leadtime10.show_plot(leadtime10.model_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadtime10.score_S\n",
    "print(f\"Best RMSE:{leadtime10.best_score_S}\")\n",
    "\n",
    "leadtime10.score_M\n",
    "print(f\"Best RMSE:{leadtime10.best_score_M}\")\n",
    "\n",
    "leadtime10.score_L\n",
    "print(f\"Best RMSE:{leadtime10.best_score_L}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 선행시간 60분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선행시간 60분 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadtime60=LeadtimeModel(ppd_data,60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선행시간 60분 모델 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 선행시간 60분 모델 결과 PLOT\n",
    "leadtime60.show_plot(leadtime60.model_S)\n",
    "leadtime60.show_plot(leadtime60.model_M)\n",
    "leadtime60.show_plot(leadtime60.model_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadtime60.score_S\n",
    "print(f\"Best RMSE:{leadtime60.best_score_S}\")\n",
    "\n",
    "leadtime60.score_M\n",
    "print(f\"Best RMSE:{leadtime60.best_score_M}\")\n",
    "\n",
    "leadtime60.score_L\n",
    "print(f\"Best RMSE:{leadtime60.best_score_L}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 선행시간 180분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선행시간 180분 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadtime180=LeadtimeModel(ppd_data,180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선행시간 180분 모델 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 선행시간 180분 모델 결과 PLOT\n",
    "leadtime180.show_plot(leadtime180.model_S)\n",
    "leadtime180.show_plot(leadtime180.model_M)\n",
    "leadtime180.show_plot(leadtime180.model_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadtime180.score_S\n",
    "print(f\"Best RMSE:{leadtime180.best_score_S}\")\n",
    "\n",
    "leadtime180.score_M\n",
    "print(f\"Best RMSE:{leadtime180.best_score_M}\")\n",
    "\n",
    "leadtime180.score_L\n",
    "print(f\"Best RMSE:{leadtime180.best_score_L}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 선행시간 360분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선행시간 360분 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadtime360=LeadtimeModel(ppd_data,360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선행시간 360분 모델 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 선행시간 360분 모델 결과 PLOT\n",
    "leadtime360.show_plot(leadtime360.model_S)\n",
    "leadtime360.show_plot(leadtime360.model_M)\n",
    "leadtime360.show_plot(leadtime360.model_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadtime360.score_S\n",
    "print(f\"Best RMSE:{leadtime360.best_score_S}\")\n",
    "\n",
    "leadtime360.score_M\n",
    "print(f\"Best RMSE:{leadtime360.best_score_M}\")\n",
    "\n",
    "leadtime360.score_L\n",
    "print(f\"Best RMSE:{leadtime360.best_score_L}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 선행시간 540분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선행시간 540분 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadtime540=LeadtimeModel(ppd_data,540)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 선행시간 540분 모델 결과 PLOT\n",
    "leadtime540.show_plot(leadtime540.model_S)\n",
    "leadtime540.show_plot(leadtime540.model_M)\n",
    "leadtime540.show_plot(leadtime540.model_L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 선행시간 720분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선행시간 720분 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadtime720=LeadtimeModel(ppd_data,720)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선행시간 720분 모델 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 선행시간 720분 모델 결과 PLOT\n",
    "leadtime720.show_plot(leadtime720.model_S)\n",
    "leadtime720.show_plot(leadtime720.model_M)\n",
    "leadtime720.show_plot(leadtime720.model_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadtime720.score_S\n",
    "print(f\"Best RMSE:{leadtime720.best_score_S}\")\n",
    "\n",
    "leadtime720.score_M\n",
    "print(f\"Best RMSE:{leadtime720.best_score_M}\")\n",
    "\n",
    "leadtime720.score_L\n",
    "print(f\"Best RMSE:{leadtime720.best_score_L}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 선행시간 1440분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선행시간 1440분 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadtime1440=LeadtimeModel(ppd_data,1440)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선행시간 1440분 모델 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 선행시간 1440분 모델 결과 PLOT\n",
    "leadtime1440.show_plot(leadtime1440.model_S)\n",
    "leadtime1440.show_plot(leadtime1440.model_M)\n",
    "leadtime1440.show_plot(leadtime1440.model_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadtime1440.score_S\n",
    "print(f\"Best RMSE:{leadtime1440.best_score_S}\")\n",
    "\n",
    "leadtime1440.score_M\n",
    "print(f\"Best RMSE:{leadtime1440.best_score_M}\")\n",
    "\n",
    "leadtime1440.score_L\n",
    "print(f\"Best RMSE:{leadtime1440.best_score_L}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadtime10_S=leadtime10.score_S\n",
    "leadtime10_M=leadtime10.score_M\n",
    "leadtime10_L=leadtime10.score_L\n",
    "\n",
    "leadtime60_S=leadtime60.score_S\n",
    "leadtime60_M=leadtime60.score_M\n",
    "leadtime60_L=leadtime60.score_L\n",
    "\n",
    "leadtime180_S=leadtime180.score_S\n",
    "leadtime180_M=leadtime180.score_M\n",
    "leadtime180_L=leadtime180.score_L\n",
    "\n",
    "leadtime360_S=leadtime360.score_S\n",
    "leadtime360_M=leadtime360.score_M\n",
    "leadtime360_L=leadtime360.score_L\n",
    "\n",
    "leadtime720_S=leadtime720.score_S\n",
    "leadtime720_M=leadtime720.score_M\n",
    "leadtime720_L=leadtime720.score_L\n",
    "\n",
    "leadtime1440_S=leadtime1440.score_S\n",
    "leadtime1440_M=leadtime1440.score_M\n",
    "leadtime1440_L=leadtime1440.score_L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전체 선행시간 결과 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=[]\n",
    "leadtime=[10,60,180,360,720,1440]\n",
    "\n",
    "for lt in leadtime:\n",
    "    df_name = f'leadtime{lt}'\n",
    "    \n",
    "    globals()[df_name+\"_S\"]['name']=df_name+'_S'\n",
    "    globals()[df_name+\"_S\"]['month']=globals()[df_name+\"_S\"].index\n",
    "    globals()[df_name+\"_M\"]['name']=df_name+'_M'\n",
    "    globals()[df_name+\"_M\"]['month']=globals()[df_name+\"_M\"].index\n",
    "    globals()[df_name+\"_L\"]['name']=df_name+'_L'\n",
    "    globals()[df_name+\"_L\"]['month']=globals()[df_name+\"_L\"].index\n",
    "    \n",
    "    result.extend([globals()[df_name+\"_S\"], globals()[df_name+\"_M\"], globals()[df_name+\"_L\"]])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_result= pd.concat(result,ignore_index=True)\n",
    "total_result=total_result[['Monthly','Flood','Total','Best Model','name','month']]\n",
    "total_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_result.pivot_table(index=['month', 'Best Model'], aggfunc='size').unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추가 feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data=ppd_data[(ppd_data.index.year==2023) & (ppd_data['wl_jamsu']>500)][['wl_jamsu','rf_songjeong','rf_daegog','rf_zingwan']]\n",
    "\n",
    "filtered_index = filtered_data.index\n",
    "\n",
    "# 이전 3개의 행에 해당하는 인덱스 계산\n",
    "previous_indices = filtered_index.union(filtered_index - pd.DateOffset(minutes=10))\n",
    "previous_indices = previous_indices.union(filtered_index - pd.DateOffset(minutes=20))\n",
    "previous_indices = previous_indices.union(filtered_index - pd.DateOffset(minutes=30))\n",
    "\n",
    "# 이전 3개의 행 가져오기\n",
    "previous_data = ppd_data.loc[previous_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 누적강수량 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppd_data2=ppd_data.copy()\n",
    "ppd_data2['rf_zingwan_sum'] =  ppd_data2['rf_zingwan'].rolling(window=144).sum()\n",
    "ppd_data2['rf_daegog_sum'] = ppd_data2['rf_daegog'].rolling(window=144).sum()\n",
    "ppd_data2['rf_songjeong_sum'] = ppd_data2['rf_songjeong'].rolling(window=144).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppd_data2['rf_zingwan_sum']= ppd_data2['rf_zingwan_sum'].fillna(ppd_data2['rf_zingwan'].cumsum())\n",
    "ppd_data2['rf_daegog_sum']= ppd_data2['rf_daegog_sum'].fillna(ppd_data2['rf_daegog'].cumsum())\n",
    "ppd_data2['rf_songjeong_sum']= ppd_data2['rf_songjeong_sum'].fillna(ppd_data2['rf_songjeong'].cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppd_data2.drop(['rf_zingwan','rf_daegog','rf_songjeong'],axis=1,inplace=True)\n",
    "ppd_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data=ppd_data2[ (ppd_data2['wl_jamsu']>500)][['wl_jamsu','rf_songjeong_sum','rf_daegog_sum','rf_zingwan_sum']]\n",
    "\n",
    "filtered_index = filtered_data.index\n",
    "\n",
    "# 이전 3개의 행에 해당하는 인덱스 계산\n",
    "previous_indices = filtered_index.union(filtered_index - pd.DateOffset(minutes=10))\n",
    "previous_indices = previous_indices.union(filtered_index - pd.DateOffset(minutes=20))\n",
    "previous_indices = previous_indices.union(filtered_index - pd.DateOffset(minutes=30))\n",
    "\n",
    "# 이전 3개의 행 가져오기\n",
    "previous_data = ppd_data2.loc[previous_indices]\n",
    "\n",
    "# 결과 출력\n",
    "a=previous_data[['wl_jamsu','rf_songjeong_sum','rf_daegog_sum','rf_zingwan_sum']]\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이전 결과와 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadtime1440=LeadtimeModel(ppd_data,1440)\n",
    "leadtime1440.model_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadtime1440_2=LeadtimeModel(ppd_data2,1440)\n",
    "leadtime1440_2.train(save=False)\n",
    "leadtime1440_2.model_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadtime1440.show_plot(leadtime1440.model_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadtime1440_2.show_plot(leadtime1440_2.model_S)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wl_predict",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
